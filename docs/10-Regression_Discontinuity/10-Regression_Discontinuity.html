<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>STAT 391: Applied Causal Inference</title>
    <meta charset="utf-8" />
    <meta name="author" content="Anthony Scotina" />
    <script src="libs/header-attrs-2.6/header-attrs.js"></script>
    <link href="libs/countdown-0.3.5/countdown.css" rel="stylesheet" />
    <script src="libs/countdown-0.3.5/countdown.js"></script>
    <script src="libs/kePrint-0.0.1/kePrint.js"></script>
    <link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="my-theme.css" type="text/css" />
    <link rel="stylesheet" href="my-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# STAT 391: Applied Causal Inference
## Regression Discontinuity
### Anthony Scotina

---








&lt;!--
pagedown::chrome_print("~/Dropbox/Teaching/03-Simmons Courses/MATH228-Introduction to Data Science/Lecture Slides/01-Introduction/01-Introduction.html")
--&gt;

class: center, middle, frame

# The Return of Arbitrary Cutoffs!

---

# Quasi-Experiments

**Context** isolates the pathway between *treatment* and *outcome* in .display3[observational data]. 

&gt; Treatment assignment is **"as if" random**, though (e.g., through nature, government intervention, eligibility cutoff, etc.). 

--

.display2[Types of quasi-experimental designs]

**1.** .display1[Difference-in-Differences]

- **Treatment/Control** groups are compared *before/after* (i.e., .display1[over time]).

--

**2.** .display3[Regression Discontinuity]

- Access to **treatment** is determined by .display3[arbitrary cutoffs/rules]. 

- If you're above the threshold, you're in the treatment group!

---

# PiÃ©chart University Statistics Requirement

**PiÃ©chart University**&lt;sup&gt;[*]&lt;/sup&gt; requires all incoming students to demonstrate competency in statistics. 

.display3[Two ways to demonstrate "competency"] ðŸ‘‡

**1.** Pass an .display1[entrance exam] with a score *higher than 70%*. 

**2.** Those who score *70 or lower* have to take a (**free**) .display2[Introductory Statistics] course in their first year. 

&gt; We want to see if this course actually "works." To do so, we'll have students take an "exit exam" at the end of the first year. 

&gt; **Is there a causal effect of taking Intro Stats on exit exam score**?

.footnote[
[*] the "t" is silent
]

---

# The Target Trial

.display1[First:]

In your **breakout groups**, briefly discuss how you might check for a causal effect of `Intro Stats` on `Exit Exam Score` in a .display3[randomized trial]. 

- Assume you have *unlimited funds and resources*.
    - Remember, this is the **target** trial!

<div class="countdown" id="timer_607e2197" style="right:0;bottom:0;" data-warnwhen="0">
<code class="countdown-time"><span class="countdown-digits minutes">02</span><span class="countdown-digits colon">:</span><span class="countdown-digits seconds">00</span></code>
</div>

---

# PiÃ©chart University Statistics Requirement



![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-5-1.png)&lt;!-- --&gt;

--

.display2[Running Variable]: Variable that determines *eligibility* for intervention

.display3[Cutoff]: Number that formally assigns access to intervention

---

# PiÃ©chart University DAG

.pull-left[
&lt;img src="10-Regression_Discontinuity_files/figure-html/unnamed-chunk-6-1.png" width="100%" /&gt;
]

.pull-right[
&lt;img src="10-Regression_Discontinuity_files/figure-html/unnamed-chunk-7-1.png" width="100%" /&gt;
]

---

# Comparable Groups: Intuition

How can we estimate **causal** effects by comparing the `Intro Stats` and `No Intro Stats` groups? 

- Didn't they score *very differently* on the entrance exam? ðŸ¤”

--

The students **right before** and **right after** the 70% threshold are *essentially the same*!

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-8-1.png)&lt;!-- --&gt;

---

# Comparable Groups: Intuition

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

- We have .display1[quasi-experimental] **treatment and control groups**!

We can compare the **outcomes** (Exit Exam Score) for students right *before/after* the threshold!

---

# Regression Discontinuity Design

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-10-1.png)&lt;!-- --&gt;

---

# Regression Discontinuity Design

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

class: center, middle, frame

# Regression Discontinuity

## The Details

---

# Goal of Regression Discontinuity

Measure the **gap** in outcome for people on *both sides* of the **cutoff**. 

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-12-1.png)&lt;!-- --&gt;

The **gap** is the .display2[local average treatment effect (LATE)]!

---

# LATE

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---

# What type of model?

The size of the gap (i.e., the **LATE**) depends what types of models you use on each side of the cutoff. 

- These considerations can have significant impact on the estimate of the **LATE**!

.pull-left[
.display2[Some considerations] ðŸ‘‡

- Parametric models 
    - e.g., **linear regression**

- Non-parametric models

- How do we measure the gap?

- .display3[Bandwidths] 
    - How many to include on either side of cutoff?
]

--

.pull-right[
&lt;img src="box.jpg" width="50%" /&gt;

*All models are wrong, but some are useful*. 
- George Box, famous statistician
]

---

# RDD with Parametric Models

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-15-1.png)&lt;!-- --&gt;

.display1[How do we measure the gap?]

- **Simplest way**: .display2[Re-center] the **running variable** around the **cutoff**. 
    - Subtract the **cutoff** from each *observed* outcome

---

# Re-centering the Running Variable


```r
piechart_data  = piechart_data %&gt;%
  mutate(entrance_centered = entrance_exam - 70)
```

&lt;table&gt;
 &lt;thead&gt;
  &lt;tr&gt;
   &lt;th style="text-align:right;"&gt; id &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; entrance_exam &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; entrance_centered &lt;/th&gt;
   &lt;th style="text-align:left;"&gt; intro_stats &lt;/th&gt;
   &lt;th style="text-align:right;"&gt; exit_exam &lt;/th&gt;
  &lt;/tr&gt;
 &lt;/thead&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 580 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 93 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 23 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; No Intro Stats &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 63 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 868 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 94 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 24 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; No Intro Stats &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 82 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 556 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 62 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -8 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Intro Stats &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 75 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 353 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 57 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; -13 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; Intro Stats &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 69 &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:right;"&gt; 845 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 84 &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 14 &lt;/td&gt;
   &lt;td style="text-align:left;"&gt; No Intro Stats &lt;/td&gt;
   &lt;td style="text-align:right;"&gt; 66 &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

`$$\hat{y}=\beta_{0}+\beta_{1}\text{Running Variable (re-centered)} + \beta_{2}\text{Treatment}$$`

- **LATE** = `\(\beta_{2}\)`

--

.display1[In this example] ðŸ‘‡

`$$\widehat{Exit Exam}=\beta_{0}+\beta_{1}\text{Entrance Exam (re-centered)} + \beta_{2}\text{Intro Stats}$$`

- **LATE** = `\(\beta_{2}\)`

---

# RDD with Parametric Models

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;

.pull-left[

```r
rdd_model1 = 
  lm(exit_exam ~ entrance_centered + 
       intro_stats, 
     data = piechart_data)
```
]

.pull-right[

```r
tidy(rdd_model1)
```

```
## # A tibble: 3 x 5
##   term                   estimate std.error statistic  p.value
##   &lt;chr&gt;                     &lt;dbl&gt;     &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt;
## 1 (Intercept)              60.5      0.417      145.  0.      
## 2 entrance_centered         0.471    0.0249      18.9 1.29e-68
## 3 intro_statsIntro Stats    9.44     0.777       12.1 9.49e-32
```

- **LATE = 9.44**
]

---

# Practice

.center[
## Do you think that LATE is a causal effect?
]

--

.display2[In your breakout group]:

Perform the same regression analysis, but look at a **smaller window of of observations**. 

- In other words, restrict your analysis to *only* students with `entrance exam` scores within **a few points of the cutoff**. 
    - Â± 10 points? 
    - Â± 5 points?
    
- Use your assigned **bandwidth** to see how your **LATE** estimate compares to the one we found earlier!


```r
# Template
rdd_model = lm(exit_exam ~ entrance_centered + intro_stats, 
     data = filter(piechart_data, 
                   entrance_centered &gt;= -X &amp;
                     entrance centered &lt;= X))
```

---

# Bandwidths

.display2[Bandwidth] = .display3[window around cutoff]

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-22-1.png)&lt;!-- --&gt;

Our **LATE** of 9.44 *probably* wasn't a causal effect, and our model was *very* **wrong**!

- All we really care about is **the area right around the cutoff**. 

Observations far away from the cutoff are *not* .display1[comparable]! 

---

# Bandwidths

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-23-1.png)&lt;!-- --&gt;![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-23-2.png)&lt;!-- --&gt;

---

# RDD with Non-parametric Models

.display2[Non-parameteric] models do not have **parameters**!

- By default, `geom_smooth()` uses **LOESS smoothing**. 
    - **Lo**cally **e**stimated **s**catterplot **s**moothing

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;

**Note**: You can't use *linear regression* to find the **LATE**. 

- Use the `rdrobust` package!

---

# `rdrobust`

![](10-Regression_Discontinuity_files/figure-html/unnamed-chunk-25-1.png)&lt;!-- --&gt;


```r
rdd_model_np = rdrobust(y = piechart_data$exit_exam, 
                        x = piechart_data$entrance_exam, 
                        c = 70)
summary(rdd_model_np)
```

**LATE = 9.862** (the `rdrobust` package flipped the sign)
- But don't forget **bandwidths**!

---

# Some cool `rdrobust` package functions

- `rdrobust()`: builds the non-parameteric RDD model

- `rdbwselect()`: runs an algorithm that selects the optimal *bandwidth*

- `rdplot()`: creates a regression discontinuity plot

---

class: center, middle, frame

# RDD Concerns

---

# RDD Concerns

In your **breakout groups**, think about possible *concerns* or *limitations* of a causal analysis that uses **regression discontinuity**. 

**Some ideas**:

- .display1[Generalizability]
    - What group(s) does the **LATE** actually apply to?

- .display2[Manipulation]
    - What if people know about the cutoff?
    
- .display3[Noncompliance]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"countIncrementalSlides": false,
"highlightLines": true
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
